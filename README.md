![Renewable Energy Forecast Banner](assets/banner.png)
[![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)](https://www.python.org/)[![PyTorch](https://img.shields.io/badge/PyTorch-2.7.1-EE4C2C?logo=pytorch)](https://pytorch.org/)![Made with ML](https://img.shields.io/badge/Made%20with-ML-blueviolet?logo=openai)[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

# âš¡ End-to-End Deep Learning for Renewable Energy Forecasting in Germany ğŸ‡©ğŸ‡ª

## ğŸ“– Table of Contents

- [1. ğŸŒ Project Overview](#1-project-overview)
- [2. ğŸ“Š Key Findings & Results](#2-key-findings--results)
- [3. ğŸ“ˆ Visualizations](#3-visualizations)
- [4. ğŸ§  Methodology and Workflow](#4-methodology-and-workflow)
- [5. ğŸ› ï¸ Technologies Used](#5-technologies-used)
- [6. ğŸ—‚ï¸ Project Structure](#6-project-structure)
- [7. ğŸš€ How to Run This Project](#7-how-to-run-this-project)
- [8. ğŸ“£ Acknowledgments](#9-acknowledgments)
---

## 1. ğŸŒ Project Overview

This project presents an end-to-end deep learning solution for forecasting hourly renewable energy generation in Germany. As Germany's *Energiewende* (energy transition) progresses, the grid's reliance on volatile sources like wind ğŸŒ¬ï¸ and solar â˜€ï¸ increases, making accurate forecasting essential for grid stability and energy market operations.

This repository documents the entire workflow, from sourcing and processing raw multi-modal data to building, systematically tuning, and comparing custom deep learning models for various forecasting tasks.

### ğŸ“¦ Datasets Used

- ğŸ“¡ **Energy Data:** Hourly electricity generation, load, and capacity data from the [Open Power System Data (OPSD)](https://open-power-system-data.org/) platform.
- ğŸŒ¤ï¸ **Weather Data:** Historical hourly weather data for Germany sourced from the [Copernicus ERA5 Reanalysis Dataset](https://cds.climate.copernicus.eu/).

### ğŸ—ï¸ Modeles

1. **ğŸ“˜ The LSTM Baseline (`LSTMBaselineSystem`)**

ğŸ§  *Think of the LSTM as a diligent, sequential reader.*

- **ğŸ” How it works:**  
  It reads your time series data one hour at a time, in order. At each hour, it updates its "memory" (the hidden state) to keep track of important patterns it has seen so far. To predict the next hour, its decision is heavily influenced by the memory from the immediately preceding hours.

- **âœ… Its Strength:**  
  This makes it extremely good at capturing short-term momentum and autocorrelation. It excels at answering the question, *"Given what just happened, what is most likely to happen next?"*

- **âš ï¸ Its Weakness:**  
  Over very long sequences, its memory can sometimes fade , making it harder to connect patterns from many days ago to the current moment.

1. **ğŸ”­ The Base Transformer (`TransformerSystem`)**

ğŸ§  *Think of the Transformer as a strategic analyst with a panoramic view.*

- **ğŸ” How it works:**  
  Instead of reading step-by-step, it looks at the entire lookback window (e.g., a full week ) all at once. Its superpower is the self-attention mechanism , which allows it to weigh the importance of every hour relative to every other hour.  
  For example, it can learn that for predicting a sunny afternoon, the weather from 24 hours ago might be more important than the weather from 18 hours ago.

- **âœ… Its Strength:**  
  It's brilliant at finding long-range dependencies and complex, non-obvious relationships across the entire dataset.

- **âš ï¸ Its Weakness:**  
  For very short-term forecasts, this powerful attention mechanism can sometimes be *overkill* â€” getting distracted by the big picture when the most important signal was simply what happened in the last hour.

1. **ğŸ‘¥ The Channel-Independent Transformer (`TransformerSystem2`)**

ğŸ§  *Think of this as an over-specialized team of analysts.*

- **ğŸ” How it works:**  
  This was an advanced version of the base Transformer. Instead of looking at all features at once, it assigned a **specialist** to each one.  
  One part of the model only looked at **solar**, another at **wind**, another at **load**, and so on. Then, at the end, they all got together to make a decision.

1. **ğŸ“ The Sophisticated Head Transformer (`TransformerSystem3`)**

ğŸ§  *Think of this as an analyst with a different reporting style.*

- **ğŸ” How it works:**  
  This model used the same input as the successful base Transformer. The only difference was in the **final step**.  
  Instead of taking all the information from the encoder and flattening it into one big pile , it tried a more structured, **two-stage process** to "read out" the results.

- **âŒ Why it didn't improve:**  
  The results showed this didn't help.  
  This is a classic finding in machine learning: sometimes the **simplest** and most **direct** method (like the base modelâ€™s flattening approach) is the most effective âœ… â€” and adding extra complexity doesn't provide any benefit .

### ğŸ‘©ğŸ»â€ğŸ”¬ Experiments

for most experiments i used the baseline of below:

- 168 hours (1 week) lookback window
- 6 hours forecast
- and the combined energy forecast

---

## 2. ğŸ“Š Key Findings & Results

The primary goal was to develop a model that could accurately forecast renewable energy generation. The project yielded several key insights through rigorous experimentation:

1. ğŸ” **LSTM Dominates ALL Forecasts:** LSTM consistently outperformed Transformer models.
2. âš–ï¸ **The optimal lookbackwindow for LSTM and the Transformer for 6-hour forecasts:** the optimal lookbackwindow for LSTM is 48 hours and for the Transformer is 24 hours
3. ğŸŒŠ **Offshore Wind is the Most Difficult to Predict:** Higher MAE due to data scarcity and complex weather patterns over the sea.
4. ğŸ•’ **Transformer vs Transformer2 vs Transformer3:** even though Transformer2 outperforms the other 2 models it takes significantly longer to train (about 42 times longer) so we used the base transformer because of it's speed and acceptable performance.

---

## 3. ğŸ“ˆ Visualizations

### ğŸ“‰ Performance vs. Forecast Horizon

Test MAE for LSTM and Transformer models across different forecast horizons:

| ğŸŒ Combined Renewables | â˜€ï¸ Solar Generation | ğŸŒ¬ï¸ Wind Generation |
| :---: | :---: | :---: |
| ![Combined Forecast](results/combined_lstm_vs_transformer_1week_lookback_6hour_predict.png) | ![Solar Forecast](results/solar_lstm_vs_transformer_1week_lookback_6hour_predict.png) | ![Wind Forecast](results/combined_wind_lstm_vs_transformer_1week_lookback_6hour_predict.png) |

### ğŸ”¬ Performance Analysis

| ğŸï¸ Onshore vs. Offshore Wind | ğŸ” Lookback Comparison | ğŸ§  Transformer Architectures |
| :---: | :---: | :---: |
| ![Onshore vs Offshore](results/offshorewind_vs_onshorewind_lstm_1week_lookback_6hour_predict.png) | ![Lookback Comparison](results/combined_lstm_vs_transformer_lookback_compare_6hour_predict.png) | ![Transformer Architectures](results/combined_transformer_vs_transformer2_transformer3_1week_lookback_6hour_predict.png) |

---

## 4. ğŸ§  Methodology and Workflow

### ğŸ“¥ 4.1. Data Sourcing and Engineering

- ğŸŒ **API Data Retrieval** using `cdsapi` and OPSD.
- ğŸ’¾ **Efficient Data Pipeline** with retries and memory-safe chunking.
- ğŸ§¹ **Data Cleaning & Merging** using timestamp joins and interpolation.

### ğŸ§® 4.2. Preprocessing and Feature Engineering

- ğŸ” **Lag & Rolling Features**
- ğŸ•°ï¸ **Cyclical Time Features**
- ğŸ§¯ **Leakage Prevention**

### ğŸ—ï¸ 4.3. Modeling

- âš¡ **LSTM Baseline:** 2-layer benchmark model.
- ğŸ”€ **Transformer Variants:**
  1. `TransformerSystem` (Base)
  2. `TransformerSystem2` (Chanel-Independent)
  3. `TransformerSystem3` (Sophisticated Head)

### ğŸ¯ 4.4. Hyperparameter Optimization

- ğŸ§ª **Optuna for Smart Tuning**
- âœ‚ï¸ **Early Pruning for Speed**

### ğŸ§ª 4.5. Experiment

---

## 5. ğŸ› ï¸ Technologies Used

- ğŸ’» **Programming:** Python
- ğŸ“š **Libraries:** Pandas, NumPy, Xarray, Scikit-learn
- ğŸ¤– **Deep Learning:** PyTorch + Lightning
- ğŸ¯ **Tuning:** Optuna
- â˜ï¸ **Data Access:** `cdsapi`

---

## 6. ğŸ—‚ï¸ Project Structure

``` bash
renewable-energy-forecast/
â”œâ”€â”€ assets/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ Open_Power_System_Data/
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ models.py
â”‚ â”œâ”€â”€ objective_optuna.py
â”‚ â””â”€â”€ main.py
â”œâ”€â”€ notebooks/
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ lightning_logs/
â”œâ”€â”€ results/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## 7. ğŸš€ How to Run This Project

### ğŸ“‹ 7.1. Prerequisites

- Python 3.10+
- Conda (recommended)
- CDS API key ğŸ“Œ

### ğŸ§ª 7.2. Running the Code

- ğŸ§¼ `preprocess.py`: Downloads and cleans data

- ğŸ§  `models.py`: Contains model classes

- ğŸ” `objective_optuna.py`: Defines tuning objectives

- ğŸš€ `main.py:` Launches the experiments

## 8. ğŸ“£ Acknowledgments

This project would not have been possible without the high-quality, open-access data provided by the following organizations:

- **Open Power System Data (OPSD)** for the comprehensive German electricity grid data.
- **Copernicus Climate Change Service (C3S)** for providing the ERA5 reanalysis weather data.
